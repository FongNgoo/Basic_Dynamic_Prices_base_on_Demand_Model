{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1aodcQNABvKrqFC2plmWzoddJWC7RoQBN","authorship_tag":"ABX9TyO1EZNExRJl8teX5JWrd7y1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install nbconvert"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UsPdaf8ayE7X","executionInfo":{"status":"ok","timestamp":1763394134684,"user_tz":-420,"elapsed":7577,"user":{"displayName":"Phong Ngô","userId":"07611069300643382823"}},"outputId":"2ff9f736-f187-45ea-c4ab-fc7f917b4198"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nbconvert in /usr/local/lib/python3.12/dist-packages (7.16.6)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (4.13.5)\n","Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert) (6.3.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert) (0.7.1)\n","Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (3.1.6)\n","Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (5.9.1)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert) (0.3.0)\n","Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (3.0.3)\n","Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (3.1.4)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (0.10.2)\n","Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (5.10.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from nbconvert) (25.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (1.5.1)\n","Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (2.19.2)\n","Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (5.7.1)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert) (0.5.1)\n","Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert) (1.4.0)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.7->nbconvert) (4.5.0)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from nbclient>=0.5.0->nbconvert) (7.4.9)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.7->nbconvert) (2.21.2)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.7->nbconvert) (4.25.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert) (2.8)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert) (4.15.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (25.4.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (2025.9.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.37.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.28.0)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (0.4)\n","Requirement already satisfied: nest-asyncio>=1.5.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (1.6.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (2.9.0.post0)\n","Requirement already satisfied: pyzmq>=23.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (26.2.1)\n","Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (6.5.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (1.17.0)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7xd3C7p9VOlI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763394136083,"user_tz":-420,"elapsed":1373,"user":{"displayName":"Phong Ngô","userId":"07611069300643382823"}},"outputId":"ad1ebe5d-369b-4012-a7cb-5a708313c3ec"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Basic_Dynamic_Prices_base_on_Demand_Model'...\n","remote: Enumerating objects: 205, done.\u001b[K\n","remote: Counting objects: 100% (205/205), done.\u001b[K\n","remote: Compressing objects: 100% (156/156), done.\u001b[K\n","remote: Total 205 (delta 54), reused 198 (delta 47), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (205/205), 12.08 MiB | 18.66 MiB/s, done.\n","Resolving deltas: 100% (54/54), done.\n","/content/Basic_Dynamic_Prices_base_on_Demand_Model/Basic_Dynamic_Prices_base_on_Demand_Model/Basic_Dynamic_Prices_base_on_Demand_Model/Basic_Dynamic_Prices_base_on_Demand_Model/Basic_Dynamic_Prices_base_on_Demand_Model/Basic_Dynamic_Prices_base_on_Demand_Model\n"]}],"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","PPO Dynamic Pricing with Gymnasium + RPT Integrated\n","Tích hợp đầy đủ: RPT Demand → PPO Pricing → Giá đề xuất\n","Không phụ thuộc file rpt.py / news_embeding.py\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import pickle\n","import json\n","import pandas as pd\n","from datetime import datetime, timedelta\n","import os\n","import warnings\n","from typing import Tuple\n","from collections import deque\n","import gymnasium as gym\n","from gymnasium import spaces\n","import matplotlib.pyplot as plt\n","!git clone https://github.com/FongNgoo/Basic_Dynamic_Prices_base_on_Demand_Model.git\n","%cd Basic_Dynamic_Prices_base_on_Demand_Model\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","source":["# Config Set Up"],"metadata":{"id":"_prFxQFtW5cp"}},{"cell_type":"code","source":["RPT_MODEL_PATH = \"/content/drive/MyDrive/Colab_Notebooks/Basic_Dynamic_Prices_base_on_Demand_Model/Output/rpt_demand_best.pth\"\n","PREPROCESSED_NPZ = \"/content/drive/MyDrive/Colab_Notebooks/Basic_Dynamic_Prices_base_on_Demand_Model/Output/preprocessed_data.npz\"\n","SCALERS_PKL = \"/content/drive/MyDrive/Colab_Notebooks/Basic_Dynamic_Prices_base_on_Demand_Model/Output/scalers.pkl\"\n","PPO_MODEL_SAVE = \"/content/drive/MyDrive/Colab_Notebooks/Basic_Dynamic_Prices_base_on_Demand_Model/Output/ppo_pricing_best.pth\""],"metadata":{"id":"1IsRJp7SW8J_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## PPO hyperparameters"],"metadata":{"id":"980mp6JYXAyV"}},{"cell_type":"code","source":["STATE_DIM = 3 + 8 + 3 + 40 + 10 + 1  # demand + env + available + news + rev_hist(10) + current_rev = 65\n","ACTION_DIM = 3\n","HIDDEN_DIM = 256\n","PPO_EPOCHS = 4\n","CLIP_EPS = 0.2\n","GAMMA = 0.99\n","LAMBDA = 0.95\n","BATCH_SIZE = 32\n","LEARNING_RATE = 3e-4\n","MAX_GRAD_NORM = 0.5\n","PARITY_PENALTY = 1e7  # Phạt cực nặng nếu vi phạm"],"metadata":{"id":"EY0XP45tXDQV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Price Constraints\n","\n"],"metadata":{"id":"yKupZ9-QXPN1"}},{"cell_type":"code","source":["MIN_PRICE = {'single': 800000, 'double': 1200000, 'vip': 2500000}\n","MAX_PRICE = {'single': 3000000, 'double': 5000000, 'vip': 10000000}\n","\n","PRICE_PARITY = {\n","    'double_single_ratio': (1.3, 1.8),\n","    'vip_single_ratio': (2.0, 3.0)\n","}\n","\n","WINDOW_SIZE = 60  # Đã dùng đúng trong sliding window\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"CxhALgMPXS3T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load scalers\n","with open(SCALERS_PKL, 'rb') as f:\n","    scalers = pickle.load(f)\n","price_scaler = scalers['price_scaler']       # ← sửa 'price' → 'price_scaler'\n","revenue_scaler = scalers['revenue_scaler']\n","solds_scaler = scalers['solds_scaler']\n","\n","# Import RPT\n","!jupyter nbconvert --to python RPT.ipynb\n","import RPT\n","from RPT import *\n","print(\"IMPORT QUA GIT THÀNH CÔNG!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":473},"id":"uogcMfNMa4rq","executionInfo":{"status":"error","timestamp":1763394149122,"user_tz":-420,"elapsed":13015,"user":{"displayName":"Phong Ngô","userId":"07611069300643382823"}},"outputId":"29d18aab-9da9-43c7-f135-3c6355d0b233"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[NbConvertApp] Converting notebook RPT.ipynb to python\n","[NbConvertApp] Writing 10478 bytes to RPT.py\n","[AUTO] h = 144\n","   → h % (R*3) = 0 = 0\n","   → h % num_heads = 0 = 0\n","[AUTO] h = 144 → per_room: 48, per_kernel: 16, head_dim: 18\n"]},{"output_type":"error","ename":"KeyError","evalue":"'price'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1374833916.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Import RPT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jupyter nbconvert --to python RPT.ipynb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mRPT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mRPT\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"IMPORT QUA GIT THÀNH CÔNG!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/Basic_Dynamic_Prices_base_on_Demand_Model/Basic_Dynamic_Prices_base_on_Demand_Model/Basic_Dynamic_Prices_base_on_Demand_Model/Basic_Dynamic_Prices_base_on_Demand_Model/Basic_Dynamic_Prices_base_on_Demand_Model/Basic_Dynamic_Prices_base_on_Demand_Model/RPT.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSCALERS_PKL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mscalers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0mprice_scaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscalers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m# ← chỉ có price, news\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[INFO] X: {X.shape}, y_demand: {y_demand.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'price'"]}]},{"cell_type":"markdown","source":["# GIÁ HỢP LỆ (MIN/MAX + PARITY)"],"metadata":{"id":"rIe7mHi-Rhc0"}},{"cell_type":"code","source":["def is_valid_price(prices: np.ndarray) -> bool:\n","    p_s, p_d, p_v = prices\n","    if not (MIN_PRICE['single'] <= p_s <= MAX_PRICE['single'] and\n","            MIN_PRICE['double'] <= p_d <= MAX_PRICE['double'] and\n","            MIN_PRICE['vip'] <= p_v <= MAX_PRICE['vip']):\n","        return False\n","    r_ds = p_d / p_s\n","    r_vs = p_v / p_s\n","    if not (PRICE_PARITY['double_single_ratio'][0] <= r_ds <= PRICE_PARITY['double_single_ratio'][1] and\n","            PRICE_PARITY['vip_single_ratio'][0] <= r_vs <= PRICE_PARITY['vip_single_ratio'][1]):\n","        return False\n","    return True\n","\n","def project_to_valid(prices: np.ndarray) -> np.ndarray:\n","    \"\"\"Chiếu giá về vùng hợp lệ (min/max + parity)\"\"\"\n","    p = prices.copy()\n","    p[0] = np.clip(p[0], MIN_PRICE['single'], MAX_PRICE['single'])\n","    p[1] = np.clip(p[1], MIN_PRICE['double'], MAX_PRICE['double'])\n","    p[2] = np.clip(p[2], MIN_PRICE['vip'], MAX_PRICE['vip'])\n","\n","    p_s = p[0]\n","    # Điều chỉnh double\n","    min_d = max(MIN_PRICE['double'], PRICE_PARITY['double_single_ratio'][0] * p_s)\n","    max_d = min(MAX_PRICE['double'], PRICE_PARITY['double_single_ratio'][1] * p_s)\n","    p[1] = np.clip(p[1], min_d, max_d)\n","\n","    # Điều chỉnh vip\n","    min_v = max(MIN_PRICE['vip'], PRICE_PARITY['vip_single_ratio'][0] * p_s)\n","    max_v = min(MAX_PRICE['vip'], PRICE_PARITY['vip_single_ratio'][1] * p_s)\n","    p[2] = np.clip(p[2], min_v, max_v)\n","\n","    return p"],"metadata":{"id":"zN-uHZxtRXQk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# PPO ACTOR-CRITIC VỚI ACTION MASKING"],"metadata":{"id":"Qy7O1QMCRmpz"}},{"cell_type":"code","source":["class PPOActor(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(STATE_DIM, HIDDEN_DIM),\n","            nn.Tanh(),\n","            nn.Linear(HIDDEN_DIM, HIDDEN_DIM),\n","            nn.Tanh(),\n","        )\n","        self.mu_head = nn.Linear(HIDDEN_DIM, ACTION_DIM)\n","        self.log_std = nn.Parameter(torch.zeros(ACTION_DIM))\n","\n","    def forward(self, x):\n","        x = self.net(x)\n","        mu = torch.tanh(self.mu_head(x))  # [-1,1]\n","        std = torch.exp(self.log_std.clamp(-20, 2))\n","        return mu, std"],"metadata":{"id":"tS12E5RRRycm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PPOCritic(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(STATE_DIM, HIDDEN_DIM),\n","            nn.Tanh(),\n","            nn.Linear(HIDDEN_DIM, HIDDEN_DIM),\n","            nn.Tanh(),\n","            nn.Linear(HIDDEN_DIM, 1)\n","        )\n","    def forward(self, x):\n","        return self.net(x)"],"metadata":{"id":"uky7g6tiR0Ho"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PPOAgent:\n","    def __init__(self):\n","        self.actor = PPOActor().to(DEVICE)\n","        self.critic = PPOCritic().to(DEVICE)\n","        self.actor_optim = optim.Adam(self.actor.parameters(), lr=LEARNING_RATE)\n","        self.critic_optim = optim.Adam(self.critic.parameters(), lr=LEARNING_RATE)\n","\n","    def _normalize(self, prices: np.ndarray) -> np.ndarray:\n","        mins = np.array([MIN_PRICE['single'], MIN_PRICE['double'], MIN_PRICE['vip']])\n","        maxs = np.array([MAX_PRICE['single'], MAX_PRICE['double'], MAX_PRICE['vip']])\n","        return 2 * (prices - mins) / (maxs - mins + 1e-8) - 1\n","\n","    def _denormalize(self, norm_prices: np.ndarray) -> np.ndarray:\n","        mins = np.array([MIN_PRICE['single'], MIN_PRICE['double'], MIN_PRICE['vip']])\n","        maxs = np.array([MAX_PRICE['single'], MAX_PRICE['double'], MAX_PRICE['vip']])\n","        return 0.5 * (norm_prices + 1) * (maxs - mins) + mins\n","\n","    def select_action(self, state: np.ndarray) -> Tuple[np.ndarray, torch.Tensor]:\n","        state_t = torch.FloatTensor(state).unsqueeze(0).to(DEVICE)\n","        mu, std = self.actor(state_t)\n","        dist = torch.distributions.Normal(mu, std)\n","        action_norm = dist.sample()\n","        log_prob = dist.log_prob(action_norm).sum(-1)\n","\n","        action_raw = self._denormalize(action_norm.cpu().detach().numpy()[0])\n","        action_raw = project_to_valid(action_raw)  # ← MASKING\n","        action_norm_final = torch.FloatTensor(self._normalize(action_raw)).unsqueeze(0).to(DEVICE)\n","\n","        # Recalculate log_prob cho action hợp lệ\n","        log_prob_final = dist.log_prob(action_norm_final).sum(-1)\n","\n","        return action_raw, log_prob_final.detach()\n","\n","    def update(self, memory):\n","        if len(memory) < BATCH_SIZE:\n","            return\n","\n","        states = torch.FloatTensor([m[0] for m in memory]).to(DEVICE)\n","        actions = torch.FloatTensor([self._normalize(m[1]) for m in memory]).to(DEVICE)\n","        old_log_probs = torch.FloatTensor([m[2] for m in memory]).to(DEVICE)\n","        advantages = torch.FloatTensor([m[3] for m in memory]).to(DEVICE)\n","        returns = torch.FloatTensor([m[4] for m in memory]).to(DEVICE)\n","\n","        for _ in range(PPO_EPOCHS):\n","            mu, std = self.actor(states)\n","            dist = torch.distributions.Normal(mu, std)\n","            new_log_probs = dist.log_prob(actions).sum(-1, keepdim=True)\n","            entropy = dist.entropy().sum(-1, keepdim=True)\n","\n","            ratio = (new_log_probs - old_log_probs).exp()\n","            surr1 = ratio * advantages\n","            surr2 = torch.clamp(ratio, 1 - CLIP_EPS, 1 + CLIP_EPS) * advantages\n","            actor_loss = -torch.min(surr1, surr2).mean() - 0.01 * entropy.mean()\n","\n","            self.actor_optim.zero_grad()\n","            actor_loss.backward()\n","            torch.nn.utils.clip_grad_norm_(self.actor.parameters(), MAX_GRAD_NORM)\n","            self.actor_optim.step()\n","\n","            critic_loss = ((self.critic(states) - returns) ** 2).mean()\n","            self.critic_optim.zero_grad()\n","            critic_loss.backward()\n","            torch.nn.utils.clip_grad_norm_(self.critic.parameters(), MAX_GRAD_NORM)\n","            self.critic_optim.step()"],"metadata":{"id":"1-uSIFaCRmMV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ENVIRONMENT"],"metadata":{"id":"9W8uWnIKR6eh"}},{"cell_type":"code","source":["class PricingEnv:\n","    def __init__(self, X_data, news_emb_data, dates, rpt_model):\n","        self.X = X_data                    # (N, 60, 3, 24)\n","        self.news_emb = news_emb_data      # (N, 60, 40) ← quan trọng!\n","        self.dates = dates\n","        self.rpt_model = rpt_model\n","        self.capacity = np.array([30, 20, 10])  # Single, Double, VIP\n","        self.idx = 0\n","        self.revenue_history = deque(maxlen=10)  # chỉ 10 ngày gần nhất\n","\n","    def reset(self):\n","        self.idx = WINDOW_SIZE - 1          # ← FIX 1: bắt đầu từ ngày có đủ 60 ngày lịch sử\n","        self.revenue_history.clear()\n","        return self._get_state()\n","\n","    def _get_state(self):\n","        x_sample = self.X[self.idx]         # (60, 3, 24)\n","        news_sample = self.news_emb[self.idx]  # (60, 40) ← ĐÚNG!\n","\n","        # Dự báo demand cho ngày hiện tại\n","        hist_feat = x_sample[:, :, :19]     # (60, 3, 19)\n","        demand_pred = predict_demand(self.rpt_model, hist_feat, news_sample, DEVICE)\n","        demand_vec = np.array([demand_pred['single'], demand_pred['double'], demand_pred['vip']])\n","\n","        # Các thành phần state\n","        env_features = x_sample[-1, 0, 19:27]           # 8 env features ngày cuối\n","        available_rooms = x_sample[:, :, 1].sum(axis=0)  # còn trống trong 60 ngày (gợi ý xu hướng)\n","        news_today = news_sample[-1]                    # embedding ngày hiện tại (40,)\n","\n","        # Lịch sử doanh thu 10 ngày (nếu chưa đủ thì pad 0)\n","        rev_hist = np.array(list(self.revenue_history))\n","        rev_hist = np.pad(rev_hist, (10 - len(rev_hist), 0), constant_values=0)\n","\n","        current_revenue = np.sum(x_sample[:, :, 0] * x_sample[:, :, 2])  # doanh thu thực tế 60 ngày qua\n","\n","        state = np.concatenate([\n","            demand_vec,          # 3\n","            env_features,        # 8\n","            available_rooms,     # 3\n","            news_today,          # 40\n","            rev_hist,            # 10\n","            [current_revenue]    # 1\n","        ]).astype(np.float32)\n","\n","        assert state.shape[0] == 65, f\"State shape sai: {state.shape}\"\n","        return state\n","\n","    def step(self, action_prices: np.ndarray):\n","        # === DOANH THU THỰC TẾ từ ngày HIỆN TẠI ===\n","        today_data = self.X[self.idx]\n","        sold_today = today_data[-1, :, 2]        # số phòng đã bán ngày hôm nay (3,)\n","        available_today = today_data[-1, :, 1]   # số phòng còn trống ngày hôm nay\n","        actual_sold = np.minimum(sold_today, available_today + sold_today)  # không âm\n","        revenue = np.sum(action_prices * actual_sold)\n","\n","        # === REWARD CHÍNH LÀ DOANH THU THỰC TẾ ===\n","        reward = revenue  # ← FIX 4: Đây mới là mục tiêu tối ưu!\n","\n","        # === PHẠT NẾU VI PHẠM GIÁ ===\n","        if not is_valid_price(action_prices):\n","            reward -= PARITY_PENALTY  # 1e7 → không bao giờ dám vi phạm\n","\n","        # === PHẠT NHẸ nếu overbook (khuyến khích không đặt quá công suất) ===\n","        overbook = np.maximum(0, sold_today - self.capacity).sum()\n","        reward -= overbook * 5000\n","\n","        # === CẬP NHẬT ===\n","        self.revenue_history.append(revenue)\n","        self.idx += 1\n","        done = self.idx >= len(self.X) - 1\n","\n","        info = {\n","            \"date\": self.dates[self.idx-1],\n","            \"revenue\": revenue,\n","            \"prices\": action_prices.tolist(),\n","            \"sold\": sold_today.tolist(),\n","            \"demand_pred\": [\n","                predict_demand(self.rpt_model, self.X[self.idx-1][:, :, :19], self.news_emb[self.idx-1], DEVICE)['single'],\n","                predict_demand(self.rpt_model, self.X[self.idx-1][:, :, :19], self.news_emb[self.idx-1], DEVICE)['double'],\n","                predict_demand(self.rpt_model, self.X[self.idx-1][:, :, :19], self.news_emb[self.idx-1], DEVICE)['vip']\n","            ]\n","        }\n","\n","        return self._get_state(), reward, done, info"],"metadata":{"id":"B_AYsCpZR7AA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# TRAINING"],"metadata":{"id":"Lk-k8TB5SDR2"}},{"cell_type":"code","source":["def plot_ppo_results(rewards_history, prices_history, demand_history, best_epoch):\n","    plt.figure(figsize=(15, 5))\n","\n","    # Plot 1: Reward over Episodes\n","    plt.subplot(1, 3, 1)\n","    plt.plot(rewards_history, label='Reward', color='#1f77b4', linewidth=2)\n","    plt.axvline(best_epoch, color='green', linestyle='--', label=f'Best: {max(rewards_history):,.0f}')\n","    plt.scatter(best_epoch, max(rewards_history), color='red', s=120)\n","    plt.title('Reward Over Episodes', fontsize=14, fontweight='bold')\n","    plt.xlabel('Episode'); plt.ylabel('Reward'); plt.grid(True); plt.legend()\n","\n","    # Plot 2: Giá đề xuất cuối cùng\n","    plt.subplot(1, 3, 2)\n","    room_types = ['Single', 'Double', 'VIP']\n","    last_prices = prices_history[-1]\n","    plt.bar(room_types, last_prices, color='#ff7f0e', alpha=0.8)\n","    plt.title('Giá Đề Xuất Cuối Cùng (VND)', fontsize=14, fontweight='bold')\n","    plt.ylabel('Giá'); plt.grid(True, axis='y')\n","\n","    # Plot 3: Demand vs Công suất\n","    plt.subplot(1, 3, 3)\n","    x = np.arange(3)\n","    width = 0.35\n","    capacity = [30, 20, 10]\n","    last_demand = demand_history[-1]\n","    plt.bar(x - width/2, capacity, width, label='Công suất (60 tổng)', color='#2ca02c')\n","    plt.bar(x + width/2, last_demand, width, label='Demand dự báo', color='#d62728')\n","    plt.xticks(x, room_types); plt.ylabel('Số phòng')\n","    plt.title('Demand vs Công suất (31/12/2025)', fontsize=14, fontweight='bold')\n","    plt.legend(); plt.grid(True, axis='y')\n","\n","    plt.suptitle('PPO Dynamic Pricing Kết Quả (2025)', fontsize=18, fontweight='bold')\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"yTA-pEUXcmHF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_ppo():\n","    print(\"=== HUẤN LUYỆN PPO VỚI PRICE PARITY & MIN/MAX ===\")\n","    rpt_model = RPTModel().to(DEVICE)\n","    rpt_model.load_state_dict(torch.load(RPT_MODEL_PATH))\n","    rpt_model.eval()\n","\n","    data = np.load(PREPROCESSED_NPZ, allow_pickle=True)\n","    X, dates, news_emb_all = data['X'], data['dates'], data['news_emb']\n","\n","    env = PricingEnv(X, news_emb_all, dates, rpt_model)\n","\n","    env = PricingEnv(X, dates, rpt_model)\n","    agent = PPOAgent()\n","\n","    memory = []\n","    best_reward = -float('inf')\n","\n","    for ep in range(50):\n","        state = env.reset()\n","        total_reward = 0\n","        while True:\n","            action, log_prob = agent.select_action(state)\n","            next_state, reward, done, info = env.step(action)\n","            value = agent.critic(torch.FloatTensor(state).unsqueeze(0).to(DEVICE)).item()\n","\n","            memory.append((state, action, log_prob.item(), reward, reward + value))\n","            total_reward += reward\n","            state = next_state\n","            if done: break\n","\n","        # Update\n","        values = [m[4] for m in memory]\n","        rewards = [m[3] for m in memory]\n","        dones = [False] * (len(memory) - 1) + [True]\n","        advantages = []\n","        gae = 0\n","        for i in reversed(range(len(rewards))):\n","            delta = rewards[i] + GAMMA * values[i+1] * (1-dones[i]) - values[i]\n","            gae = delta + GAMMA * LAMBDA * (1-dones[i]) * gae\n","            advantages.insert(0, gae)\n","        returns = [a + v for a, v in zip(advantages, values)]\n","\n","        for i, m in enumerate(memory):\n","            m = list(m); m[3] = advantages[i]; m[4] = returns[i]; memory[i] = tuple(m)\n","        agent.update(memory)\n","        memory.clear()\n","\n","        print(f\"Ep {ep+1:2d} | Reward: {total_reward:,.0f} | \"\n","              f\"Giá: {action[0]:,.0f} | {action[1]:,.0f} | {action[2]:,.0f}\")\n","\n","        if total_reward > best_reward and is_valid_price(action):\n","            best_reward = total_reward\n","            torch.save(agent.actor.state_dict(), PPO_MODEL_SAVE)\n","            print(\"   → Lưu model hợp lệ!\")\n","    print(f\\\"BEST REWARD: {best_reward:,.0f}\\\")\n","    plot_ppo_results(rewards_history, prices_history, demand_history, best_epoch)  # ← thêm\n","    return agent"],"metadata":{"id":"xqJzQX_KSI5u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# INFERENCE"],"metadata":{"id":"tELXuSn_SOUX"}},{"cell_type":"code","source":["def predict_tomorrow_price(agent, rpt_model, data, idx=-1):\n","    \"\"\"\n","    Dự báo giá ngày mai (31/12/2025) – ĐÃ FIX HẾT 6 LỖI\n","    \"\"\"\n","    X = data['X']                          # (N, 60, 3, 24)\n","    news_emb_all = data['news_emb']        # (N, 60, 40)\n","    dates = data['dates']\n","\n","    # === LẤY DỮ LIỆU NGÀY HIỆN TẠI (idx) ===\n","    sample_x = X[idx]                      # (60, 3, 24) – 60 ngày lịch sử tính đến hôm nay\n","    sample_news = news_emb_all[idx]        # (60, 40)  – ĐÚNG!\n","\n","    # === DỰ BÁO DEMAND CHO NGÀY MAI (dựa trên 60 ngày vừa qua) ===\n","    hist_features = sample_x[:, :, :19]    # ← FIX 1: 19 features đầu (60, 3, 19)\n","    tomorrow_demand = predict_demand(rpt_model, hist_features, sample_news, DEVICE)\n","\n","    demand_vec = np.array([\n","        tomorrow_demand['single'],\n","        tomorrow_demand['double'],\n","        tomorrow_demand['vip']\n","    ])\n","\n","    # === XÂY DỰNG STATE CHO PPO (phải giống hệt trong env) ===\n","    env_features = sample_x[-1, 0, 19:27]          # 8 env features ngày hiện tại\n","    available_rooms = sample_x[:, :, 1].sum(axis=0)  # xu hướng phòng trống\n","\n","    # News embedding ngày hiện tại (ngày cuối cùng trong cửa sổ 60 ngày)\n","    news_today = sample_news[-1]                   # ← FIX 2: (40,)\n","\n","    # Lịch sử doanh thu (nếu có trong agent, dùng thật; không thì 0)\n","    try:\n","        rev_hist = np.array(list(agent.revenue_history))[-10:]\n","        rev_hist = np.pad(rev_hist, (10 - len(rev_hist), 0), constant_values=0)\n","    except:\n","        rev_hist = np.zeros(10)\n","\n","    # Doanh thu thực tế 60 ngày qua\n","    current_revenue = np.sum(sample_x[:, :, 0] * sample_x[:, :, 2])\n","\n","    # === TẠO STATE ĐÚNG 65 CHIỀU ===\n","    state = np.concatenate([\n","        demand_vec,       # 3\n","        env_features,     # 8\n","        available_rooms,  # 3\n","        news_today,       # 40\n","        rev_hist,         # 10\n","        [current_revenue] # 1\n","    ]).astype(np.float32)\n","\n","    assert state.shape == (65,), f\"State shape sai: {state.shape}\"\n","\n","    # === DỰ ĐOÁN GIÁ ===\n","    action_raw, _ = agent.select_action(state)\n","    action_raw = np.clip(action_raw,\n","                         [200, 400, 600],\n","                         [500, 700, 1500])  # đảm bảo trong min/max\n","\n","    tomorrow_date = pd.to_datetime(dates[idx]) + pd.Timedelta(days=1)\n","\n","    print(f\"\\n{'='*50}\")\n","    print(f\"   GIÁ ĐỀ XUẤT NGÀY {tomorrow_date.strftime('%d/%m/%Y')} (CAO ĐIỂM TẾT)\")\n","    print(f\"{'='*50}\")\n","    print(f\"   • Single : {action_raw[0]:,.0f} VND\")\n","    print(f\"   • Double : {action_raw[1]:,.0f} VND\")\n","    print(f\"   • VIP    : {action_raw[2]:,.0f} VND\")\n","    print(f\"   • Tỷ lệ  : D/S = {action_raw[1]/action_raw[0]:.2f} | V/S = {action_raw[2]/action_raw[0]:.2f}\")\n","    print(f\"   • Demand : {sum(tomorrow_demand.values()):.0f} phòng (vượt {sum(tomorrow_demand.values())-60:.0f} so với công suất 60)\")\n","    print(f\"{'='*50}\")\n","\n","    return action_raw"],"metadata":{"id":"CXXTowrRSP0F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Main"],"metadata":{"id":"dUlS01oWSSqc"}},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    agent = train_ppo()\n","    data = np.load(PREPROCESSED_NPZ, allow_pickle=True)\n","    rpt_model = RPTModel().to(DEVICE)\n","    rpt_model.load_state_dict(torch.load(RPT_MODEL_PATH))\n","    rpt_model.eval()\n","\n","    # Load best PPO\n","    agent.actor.load_state_dict(torch.load(PPO_MODEL_SAVE))\n","\n","    predict_tomorrow_price(agent, rpt_model, data)"],"metadata":{"id":"h4x3h8B0SXAW"},"execution_count":null,"outputs":[]}]}